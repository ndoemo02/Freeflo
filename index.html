<!DOCTYPE html>
<html lang="pl">
<head>
<meta charset="UTF-8">
<title>FreeFlow Voice</title>
<style>
  body { font-family: sans-serif; background: #111; color: #fff; text-align: center; }
  #logoBtn { width: 120px; height: 120px; border-radius: 50%; background: #222; border: none; cursor: pointer; margin: 20px auto; display: block; }
  #logoBtn.pulse { animation: pulse 1.5s infinite; }
  @keyframes pulse {
    0% { box-shadow: 0 0 0 0 rgba(0, 255, 0, 0.7); }
    70% { box-shadow: 0 0 0 15px rgba(0, 255, 0, 0); }
    100% { box-shadow: 0 0 0 0 rgba(0, 255, 0, 0); }
  }
  #transcript { margin-top: 10px; min-height: 30px; font-size: 1.2em; }
</style>
</head>
<body>

<h1>ðŸŽ¤ FreeFlow Voice Assistant</h1>

<button id="logoBtn">ðŸŽ¤</button>
<div id="transcript">NaciÅ›nij, aby mÃ³wiÄ‡...</div>

<script>
const API_BASE = "https://twoj-projekt.vercel.app/api/chat";
let recognizing = false;
let recognition;

if ('webkitSpeechRecognition' in window) {
  recognition = new webkitSpeechRecognition();
  recognition.lang = 'pl-PL';
  recognition.interimResults = true;
  recognition.continuous = false;

  recognition.onstart = () => {
    recognizing = true;
    document.getElementById("logoBtn").classList.add("pulse");
    document.getElementById("transcript").innerText = "... sÅ‚ucham ...";
  };

  recognition.onresult = (event) => {
    let finalTranscript = "";
    for (let i = event.resultIndex; i < event.results.length; ++i) {
      const transcript = event.results[i][0].transcript;
      if (event.results[i].isFinal) {
        finalTranscript += transcript;
      } else {
        document.getElementById("transcript").innerText = transcript;
      }
    }
    if (finalTranscript) {
      document.getElementById("transcript").innerText = finalTranscript;
      askAssistant(finalTranscript);
    }
  };

  recognition.onend = () => {
    recognizing = false;
    document.getElementById("logoBtn").classList.remove("pulse");
  };
}

document.getElementById("logoBtn").addEventListener("click", () => {
  if (recognizing) {
    recognition.stop();
    return;
  }
  recognition.start();
});

async function askAssistant(userText) {
  const res = await fetch(API_BASE, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      messages: [{ role: "user", content: userText }],
      system: "JesteÅ› pomocnym asystentem gÅ‚osowym FreeFlow, odpowiadasz krÃ³tko i konkretnie po polsku.",
      temperature: 0.4
    })
  });

  const data = await res.json();
  if (data.success) {
    speak(data.reply);
  } else {
    speak("WystÄ…piÅ‚ bÅ‚Ä…d serwera");
  }
}

function speak(text) {
  const utter = new SpeechSynthesisUtterance(text);
  utter.lang = "pl-PL";
  speechSynthesis.cancel();
  speechSynthesis.speak(utter);
}
</script>

</body>
  <audio id="ttsAudio" preload="auto"></audio>
  <script>
  // === KONFIG ===
  const API_URL = 'https://freeflow-backend-vercel.vercel.app/api/assistant-text';

  // elementy UI (podmieÅ„ selektory jeÅ›li masz inne)
  const micBtn = document.querySelector('#micBtn') || document.querySelector('.logo-btn') || document.querySelector('button');
  const transcriptBox = document.querySelector('#transcript') || document.querySelector('.transcript') || null;
  const player = document.getElementById('ttsPlayer');

  // Prosty helper do aktualizacji transkrypcji/logu
  function showText(where, text) {
    if (!where) return;
    where.textContent = text;
  }

  // Odtwarzanie MP3 z base64
  async function playBase64Mp3(base64) {
    try {
      // policy: audio musi wystartowaÄ‡ po GESTURE â€” klikniÄ™cie w micBtn wystarczy
      // tworzymy URL data: z base64
      const src = `data:audio/mpeg;base64,${base64}`;
      player.src = src;
      await player.play();
    } catch (err) {
      console.error('Audio play error:', err);
      // fallback do web Speech
      // (czÄ™sto pomaga jednorazowy gest: kliknij przycisk jeszcze raz)
      return false;
    }
    return true;
  }

  // Fallback jeÅ›li backend nie zwrÃ³ci audio lub autoplay siÄ™ wywali
  function speakWithWebSpeech(text, lang = 'pl-PL') {
    try {
      const u = new SpeechSynthesisUtterance(text);
      u.lang = lang;
      window.speechSynthesis.cancel(); // czyÅ›cimy kolejkÄ™
      window.speechSynthesis.speak(u);
    } catch (e) {
      console.warn('speechSynthesis fallback failed:', e);
    }
  }

  // WyÅ›lij tekst do backendu i zagraj odpowiedÅº
  async function sendToAssistant(userText) {
    try {
      const res = await fetch(API_URL, {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({ text: userText })
      });

      const data = await res.json();
      if (!data.success) {
        console.warn('Assistant error:', data);
        speakWithWebSpeech('WystÄ…piÅ‚ bÅ‚Ä…d po stronie serwera.');
        return;
      }

      // Tekst asystenta
      const answer = data.assistantText || 'Nie mam teraz odpowiedzi.';
      showText(transcriptBox, answer);

      // JeÅ›li przyszÅ‚o audio â€” sprÃ³buj odtworzyÄ‡
      if (data.audioBase64) {
        const ok = await playBase64Mp3(data.audioBase64);
        if (!ok) speakWithWebSpeech(answer); // fallback jeÅ›li autoplay siÄ™ wywaliÅ‚
      } else {
        // Brak audio w odpowiedzi â€” fallback
        speakWithWebSpeech(answer);
      }
    } catch (err) {
      console.error('Network/parse error:', err);
      speakWithWebSpeech('Nie udaÅ‚o siÄ™ poÅ‚Ä…czyÄ‡ z serwerem.');
    }
  }

  // === Minimalny tryb: rozpoznaj mowÄ… (Web Speech) â†’ wyÅ›lij do backendu ===
  // JeÅ›li masz juÅ¼ swÃ³j rozpoznawacz â€“ wywoÅ‚uj tylko sendToAssistant(transkrypcja)
  function startDictation() {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) {
      alert('Twoja przeglÄ…darka nie wspiera rozpoznawania mowy. SprÃ³buj Chrome.');
      return;
    }

    const rec = new SR();
    rec.lang = 'pl-PL';
    rec.interimResults = false;
    rec.maxAlternatives = 1;

    rec.onstart = () => showText(transcriptBox, 'SÅ‚uchamâ€¦');
    rec.onerror = (e) => showText(transcriptBox, 'BÅ‚Ä…d rozpoznawania: ' + (e.error || 'nieznany'));
    rec.onresult = (e) => {
      const txt = e.results[0][0].transcript.trim();
      showText(transcriptBox, txt);
      sendToAssistant(txt);
    };
    rec.onend = () => { /* moÅ¼na dodaÄ‡ auto-restart, ale na razie rÄ™cznie */ };

    rec.start();
  }

  // Podpinka pod przycisk (klikniÄ™cie = gest dla autoplay)
  if (micBtn) {
    micBtn.addEventListener('click', () => {
      // zatrzymaj ewentualnÄ… mowÄ™ z poprzedniej odpowiedzi
      try { window.speechSynthesis.cancel(); player.pause(); } catch {}
      startDictation();
    });
  }
</script>
</html>
