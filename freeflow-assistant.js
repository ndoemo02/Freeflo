/* FreeFlow â€“ assistant (final-only speech + przezroczyste UI)
   WysyÅ‚a do backendu TYLKO finalny tekst, nie ucina w poÅ‚owie.
   DziaÅ‚a z Web Speech API (Chrome/Android). */

(() => {
  const transcriptEl = document.getElementById("transcript");
  const micBtn = document.getElementById("micBtn");
  const ttsPlayer = document.getElementById("ttsPlayer");

  // jeÅ›li masz wÅ‚asny backend pod innÄ… domenÄ… â€“ ustaw tutaj:
  const BASE_URL = ""; // pusty = wzglÄ™dne /api/*

  // ===== Text â†’ Assistant â†’ (opcjonalnie TTS) =====
  async function sendText(text) {
    if (!text || !text.trim()) return;
    setTranscript(text);

    try {
      // 1) odpowiedÅº asystenta (tekst)
      const r = await fetch(`${BASE_URL}/api/assistant-text`, {
        method: "POST",
        headers: { "Content-Type":"application/json" },
        body: JSON.stringify({ text })
      });
      const data = await r.json();
      const reply = data?.reply || "OK.";

      setTranscript(reply);

      // 2) mowa zwrotna (jeÅ›li endpoint istnieje)
      try {
        const t = await fetch(`${BASE_URL}/api/tts`, {
          method: "POST",
          headers: { "Content-Type":"application/json" },
          body: JSON.stringify({ text: reply, voice: "pl" })
        });
        if (t.ok) {
          const { audioUrl } = await t.json();
          if (audioUrl) {
            ttsPlayer.src = audioUrl;
            ttsPlayer.play().catch(()=>{});
          }
        }
      } catch {}
    } catch (err) {
      setTranscript("BÅ‚Ä…d sieci lub backendu. SprÃ³buj ponownie.");
      console.error(err);
    }
  }
  window.sendToAssistant = sendText;

  function setTranscript(text) { transcriptEl.textContent = text; }

  // ===== Speech Recognition (tylko final) =====
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  let recognition = null;
  let listening = false;

  if (SR) {
    recognition = new SR();
    recognition.lang = "pl-PL";
    recognition.continuous = false;        // jedna wypowiedÅº = jedno nagranie
    recognition.interimResults = false;    // <â€” KLUCZOWE: tylko wynik finalny

    recognition.addEventListener("start", () => {
      listening = true;
      micBtn.classList.add("recording");
      setTranscript("Nagrywamâ€¦ mÃ³w Å›miaÅ‚o. Zwolnij przycisk, aby wysÅ‚aÄ‡.");
    });

    // pokazuj na Å¼ywo (opcjonalnie), ale nie wysyÅ‚aj jeszcze
    recognition.addEventListener("result", (e) => {
      const txt = Array.from(e.results).map(r => r[0].transcript).join("");
      if (!e.results[0].isFinal) {
        setTranscript(txt + " â€¦");
      } else {
        // final â€“ dopiero teraz wysyÅ‚amy
        setTranscript(txt);
        sendText(txt);
      }
    });

    recognition.addEventListener("error", (e) => {
      console.warn("SR error:", e.error);
      setTranscript("BÅ‚Ä…d sieci lub backendu. SprÃ³buj ponownie.");
      stopSR();
    });

    recognition.addEventListener("end", () => {
      listening = false;
      micBtn.classList.remove("recording");
    });
  } else {
    micBtn.disabled = true;
    micBtn.textContent = "ðŸŽ¤ Brak wsparcia mowy w tej przeglÄ…darce";
  }

  function startSR() {
    if (!recognition || listening) return;
    try { recognition.start(); } catch {}
  }
  function stopSR() {
    if (!recognition) return;
    try { recognition.stop(); } catch {}
  }

  // KlikniÄ™cie â€“ start/stop
  micBtn.addEventListener("mousedown", startSR);
  micBtn.addEventListener("touchstart", (e)=>{ e.preventDefault(); startSR(); }, {passive:false});
  micBtn.addEventListener("mouseup", stopSR);
  micBtn.addEventListener("mouseleave", ()=> listening && stopSR());
  micBtn.addEventListener("touchend", stopSR);

})();
